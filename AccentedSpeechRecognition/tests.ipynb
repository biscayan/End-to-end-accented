{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 960, 240])\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport config\n",
    "\n",
    "conf = config.Config()\n",
    "\n",
    "from model import MultiTask\n",
    "model = MultiTask.load_model('saved_models/SimpleDS_TRAIN__in_mfcc__out_transcripts__nblyrs-head-4-speech-1-accent-1__bnf-256__24-02-2019_23h50m00.pth')\n",
    "\n",
    "from dataloader import MultiDataset, MultiDataLoader\n",
    "import torch\n",
    "\n",
    "labels = \" 'ABCDEFGHIJKLMNOPQRSTUVWXYZ_\"\n",
    "\n",
    "\n",
    "dataset = MultiDataset('data/splits/dev.csv', labels, \n",
    "                       use_mfcc_in=model._meta['use_mfcc_in'], \n",
    "                       use_ivectors_in=True,#model._meta['use_ivectors_in'], \n",
    "                       use_embeddings_in=True,#model._meta['use_embeddings_in'],\n",
    "                       use_transcripts_out=model._meta['use_transcripts_out'], \n",
    "                       use_accents_out=model._meta['use_accents_out'])\n",
    "\n",
    "dataloader = MultiDataLoader(dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "for data in dataloader:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_mfcc_in': True,\n",
       " 'use_ivectors_in': False,\n",
       " 'use_embeddings_in': False,\n",
       " 'use_transcripts_out': True,\n",
       " 'use_accents_out': False,\n",
       " 'mfcc_size': 40,\n",
       " 'ivector_size': 100,\n",
       " 'embedding_size': 256,\n",
       " 'rnn_type': torch.nn.modules.rnn.GRU,\n",
       " 'labels': \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \",\n",
       " 'accents_dict': {'australia': 0,\n",
       "  'canada': 1,\n",
       "  'england': 2,\n",
       "  'ireland': 3,\n",
       "  'scotland': 4,\n",
       "  'us': 5,\n",
       "  'wales': 6},\n",
       " 'rnn_hidden_size': 800,\n",
       " 'nb_head_layers': 4,\n",
       " 'nb_speech_layers': 1,\n",
       " 'nb_accents_layers': 1,\n",
       " 'bidirectional': True,\n",
       " 'bottleneck_size': 256,\n",
       " 'DEBUG': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "sum([torch.tensor([2]), torch.tensor([5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t='this is test'\n",
    "i = t.find(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is test'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[i+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'exp_name_prefix': 'a',\n",
       "  'epochs': 2,\n",
       "  'labels': \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \",\n",
       "  'batch_size': 10,\n",
       "  'num_workers': 4,\n",
       "  'cuda': True,\n",
       "  'losses_mix': 0.9,\n",
       "  'learning_rate': 0.0003,\n",
       "  'mfcc_size': 40,\n",
       "  'ivector_size': 100,\n",
       "  'embedding_size': 100,\n",
       "  'rnn_type': torch.nn.modules.rnn.GRU,\n",
       "  'rnn_hidden_size': 800,\n",
       "  'nb_head_layers': 3,\n",
       "  'nb_speech_layers': 1,\n",
       "  'nb_accents_layers': 1,\n",
       "  'bidirectional': True,\n",
       "  'bottleneck_size': 256,\n",
       "  'use_mfcc_in': True,\n",
       "  'use_ivectors_in': True,\n",
       "  'use_embeddings_in': True,\n",
       "  'use_transcripts_out': True,\n",
       "  'use_accents_out': False,\n",
       "  'decoder_alpha': 0.8,\n",
       "  'decoder_beta': 1.0,\n",
       "  'decoder_cutoff_top_n': 40,\n",
       "  'decoder_cutoff_prob': 1.0,\n",
       "  'decoder_beam_width': 100,\n",
       "  'lm_path': './data/language_models/cv.lm',\n",
       "  'train_manifest': './data/splits/train.csv',\n",
       "  'dev_manifest': './data/splits/dev.csv',\n",
       "  'test_manifest': './data/splits/test.csv',\n",
       "  'tensorboard_path': './tensorboard_runs/',\n",
       "  'saved_models_path': './saved_models/'},\n",
       " {'exp_name_prefix': 'b',\n",
       "  'epochs': 2,\n",
       "  'labels': \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \",\n",
       "  'batch_size': 10,\n",
       "  'num_workers': 4,\n",
       "  'cuda': True,\n",
       "  'losses_mix': 0.9,\n",
       "  'learning_rate': 0.0003,\n",
       "  'mfcc_size': 40,\n",
       "  'ivector_size': 100,\n",
       "  'embedding_size': 100,\n",
       "  'rnn_type': torch.nn.modules.rnn.GRU,\n",
       "  'rnn_hidden_size': 800,\n",
       "  'nb_head_layers': 3,\n",
       "  'nb_speech_layers': 1,\n",
       "  'nb_accents_layers': 1,\n",
       "  'bidirectional': True,\n",
       "  'bottleneck_size': 256,\n",
       "  'use_mfcc_in': False,\n",
       "  'use_ivectors_in': True,\n",
       "  'use_embeddings_in': True,\n",
       "  'use_transcripts_out': False,\n",
       "  'use_accents_out': True,\n",
       "  'decoder_alpha': 0.8,\n",
       "  'decoder_beta': 1.0,\n",
       "  'decoder_cutoff_top_n': 40,\n",
       "  'decoder_cutoff_prob': 1.0,\n",
       "  'decoder_beam_width': 100,\n",
       "  'lm_path': './data/language_models/cv.lm',\n",
       "  'train_manifest': './data/splits/train.csv',\n",
       "  'dev_manifest': './data/splits/dev.csv',\n",
       "  'test_manifest': './data/splits/test.csv',\n",
       "  'tensorboard_path': './tensorboard_runs/',\n",
       "  'saved_models_path': './saved_models/'},\n",
       " {'exp_name_prefix': 'c',\n",
       "  'epochs': 2,\n",
       "  'labels': \"_'ABCDEFGHIJKLMNOPQRSTUVWXYZ \",\n",
       "  'batch_size': 10,\n",
       "  'num_workers': 4,\n",
       "  'cuda': True,\n",
       "  'losses_mix': 0.9,\n",
       "  'learning_rate': 0.0003,\n",
       "  'mfcc_size': 40,\n",
       "  'ivector_size': 100,\n",
       "  'embedding_size': 100,\n",
       "  'rnn_type': torch.nn.modules.rnn.GRU,\n",
       "  'rnn_hidden_size': 800,\n",
       "  'nb_head_layers': 3,\n",
       "  'nb_speech_layers': 1,\n",
       "  'nb_accents_layers': 1,\n",
       "  'bidirectional': True,\n",
       "  'bottleneck_size': 256,\n",
       "  'use_mfcc_in': True,\n",
       "  'use_ivectors_in': False,\n",
       "  'use_embeddings_in': False,\n",
       "  'use_transcripts_out': True,\n",
       "  'use_accents_out': True,\n",
       "  'decoder_alpha': 0.8,\n",
       "  'decoder_beta': 1.0,\n",
       "  'decoder_cutoff_top_n': 40,\n",
       "  'decoder_cutoff_prob': 1.0,\n",
       "  'decoder_beam_width': 100,\n",
       "  'lm_path': './data/language_models/cv.lm',\n",
       "  'train_manifest': './data/splits/train.csv',\n",
       "  'dev_manifest': './data/splits/dev.csv',\n",
       "  'test_manifest': './data/splits/test.csv',\n",
       "  'tensorboard_path': './tensorboard_runs/',\n",
       "  'saved_models_path': './saved_models/'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.patch_config('experiments.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MultiTask\n",
    "\n",
    "model = MultiTask(DEBUG=False, rnn_hidden_size=800, \n",
    "                  use_mfcc_in=conf['use_mfcc_in'], \n",
    "                  use_ivectors_in=conf['use_ivectors_in'], \n",
    "                  use_embeddings_in=conf['use_embeddings_in'],\n",
    "                  use_transcripts_out=conf['use_transcripts_out'], \n",
    "                  use_accents_out=conf['use_accents_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blib \n",
      "\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print('blib', '\\n')\n",
    "print('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'australia': 0, 'canada': 1, 'england': 2, 'us': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.accent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf['use_embeddings_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._meta['use_embeddings_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3351a1c54734de0b6fe48058fa7e33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=58), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "for data in tqdm(dataloader):\n",
    "    inputs, inputs_lens, transcripts, transcripts_lens, accents = data\n",
    "\n",
    "    \n",
    "    a, b, c, __ = model(inputs.cuda(), inputs_lens.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiTask.serialize(model, 'tmp')\n",
    "\n",
    "modelb = MultiTask.load_model('tmp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb = modelb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8850c82f6c9d4458bc727af18e20630b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=571), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(dataloader):\n",
    "    inputs, inputs_lens, transcripts, transcripts_lens, accents = data\n",
    "\n",
    "    \n",
    "    a, b, c = modelb(inputs.cuda(), inputs_lens.cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@classmethod\n",
    "def load_model(cls, path):\n",
    "    package = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "    model = cls(rnn_hidden_size=package['hidden_size'], nb_layers=package['nb_layers'],\n",
    "                labels=package['labels'], audio_conf=package['audio_conf'],\n",
    "                rnn_type=supported_rnns[package['rnn_type']], bidirectional=package.get('bidirectional', True))\n",
    "    model.load_state_dict(package['state_dict'])\n",
    "    for x in model.rnns:\n",
    "        x.flatten_parameters()\n",
    "    return model\n",
    "\n",
    "@classmethod\n",
    "def load_model_package(cls, package):\n",
    "    model = cls(rnn_hidden_size=package['hidden_size'], nb_layers=package['nb_layers'],\n",
    "                labels=package['labels'], audio_conf=package['audio_conf'],\n",
    "                rnn_type=supported_rnns[package['rnn_type']], bidirectional=package.get('bidirectional', True))\n",
    "    model.load_state_dict(package['state_dict'])\n",
    "    return model\n",
    "\n",
    "@staticmethod\n",
    "def serialize(model, optimizer=None, epoch=None, iteration=None, loss_results=None,\n",
    "              main_loss_results=None, side_loss_results=None,\n",
    "              cer_results=None, wer_results=None, mca_results=None, avg_loss=None, meta=None):\n",
    "    model = model.module if DeepSpeech.is_parallel(model) else model\n",
    "    package = {\n",
    "        'version': model._version,\n",
    "        'hidden_size': model._hidden_size,\n",
    "        'nb_layers': model._nb_layers,\n",
    "        'rnn_type': supported_rnns_inv.get(model._rnn_type, model._rnn_type.__name__.lower()),\n",
    "        'audio_conf': model._audio_conf,\n",
    "        'labels': model._labels,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'bidirectional': model._bidirectional\n",
    "    }\n",
    "    if optimizer is not None:\n",
    "        package['optim_dict'] = optimizer.state_dict()\n",
    "    if avg_loss is not None:\n",
    "        package['avg_loss'] = avg_loss\n",
    "    if epoch is not None:\n",
    "        package['epoch'] = epoch + 1  # increment for readability\n",
    "    if iteration is not None:\n",
    "        package['iteration'] = iteration\n",
    "    if loss_results is not None:\n",
    "        package['loss_results'] = loss_results\n",
    "        package['main_loss_results'] = main_loss_results\n",
    "        package['side_loss_results'] = side_loss_results\n",
    "        package['cer_results'] = cer_results\n",
    "        package['wer_results'] = wer_results\n",
    "        package['mca_results'] = mca_results\n",
    "    if meta is not None:\n",
    "        package['meta'] = meta\n",
    "    return package"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
